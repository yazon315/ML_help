{"cells":[{"cell_type":"markdown","metadata":{"id":"xMTVirWqLoSk"},"source":["# Справка по машинному обучению (ML)\n","\n","Существуют задачи:\n","- классификации;\n","- регрессии.\n","\n","Они определяются видом целевого признака (ответа).  \n","Если целевой признак (ответ) категориальный, то решается задача классификации.  \n","Если целевой признак (ответ) количественный , то решается задача регрессии."]},{"cell_type":"markdown","metadata":{"id":"3FCuTzyU8iSW"},"source":["## Деление исходных данных на выборки для обучения, тестирования и валидации\n","\n","Два варианта деления исходных данных на выборки\n","\n","Вариант 1:\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=19zp6g67gRcwAzDVhdAEUuVsaJiwSn_Zp\" alt=\"вариант 1\" width=\"60%\"/>\n","\n","Вариант 2:\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1A0Bm9UuVyOFbiinyAtB5DGjfSkRtC-tl\" alt=\"вариант 2\" width=\"60%\"/>\n"]},{"cell_type":"markdown","metadata":{"id":"DhtN3DW3erjp"},"source":["### Функция train_test_split() для деления выборки на части\n","\n","``` python\n","# импортирование функции\n","from sklearn.model_selection import train_test_split\n","# применение функции\n","df_train, df_valid = train_test_split(df, test_size=0.25, random_state=12345)\n","```\n","\n","``` python\n","# еще один пример\n","features_train, features_valid_test, target_train, target_valid_test = train_test_split(\n","  features, target, test_size=.4, random_state=5639, stratify=target)\n","```\n","\n","Функция `train_test_split()` возвращает два новых набора данных: обучающий и валидационный (тестовый).  \n","Параметры функции:\n","- `df` - название набора, данные которого делим;\n","- `test_size` - размер валидационной (или тестовой) выборки, выражается в долях: от 0 до 1 (в этом примере `0.25`, т.к. отделяем 25% исходных данных;\n","- `random_state` - любое значение , но не `None`;\n","- `stratify` - сохраняет соотношение (пропорцию) между классами целевого признака."]},{"cell_type":"markdown","metadata":{"id":"SNMCisdl2C6t"},"source":["## Модели для задач классификации"]},{"cell_type":"markdown","metadata":{"id":"tPWTCEwdEpcf"},"source":["### Метрики качества моделей для задач классификации\n","\n","В библиотеке `sklearn` метрики находятся в модуле `slearn.metrics`."]},{"cell_type":"markdown","metadata":{"id":"6XwZr8GPn2F-"},"source":["#### Confusion matrix (*матрица ошибок или матрица неточностей*)\n","\n","По главной диагонали (от верхнего левого угла) выстроены правильные прогнозы (TN в левом верхнем углу; TP в правом нижнем углу), вне главной диагонали — ошибочные варианты (FP в правом верхнем углу; FN в левом нижнем углу).\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1DtrH2trTa--9xiAyu773ZapoF5_72Fjo\" alt=\"Матрица ошибок\" width=\"30%\"/>\n","\n","Класс с меткой «1» называется положительным, с меткой «0» — отрицательным.  \n","- True Positive (TP) - истинно положительные ответы;\n","- True Negative (TN) - истинно отрицательные ответы;\n","- False Positive (FP) - ложноположительные ответы;\n","- False Negative (FN) - ложноотрицательные ответы.\n","\n","Функция `confusion_matrix()` принимает на вход верные ответы и предсказания модели, а возвращает матрицу ошибок."]},{"cell_type":"markdown","metadata":{"id":"lUkJhXzMmMch"},"source":["#### 1) **Accuracy** (*доля правильных ответов*): отношение числа правильных ответов к размеру тестовой выборки.\n","\n","$\\begin{align}\n","accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\n","\\end{align}$\n","\n","Интуитивно понятная, очевидная и почти неиспользуемая метрика. Чем *Accuracy* больше, тем точнее модель. Но эта метрика бесполезна в задачах с неравными классами (дисбаланс классов).  \n","Вычисляется функцией `accuracy_score()`. Функция принимает на вход два аргумента: правильные ответы и предсказания модели; возвращает значение *Accuracy*.\n","\n","``` python\n","from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(target, predictions)\n","```"]},{"cell_type":"markdown","metadata":{"id":"2dIzQswgmNk4"},"source":["#### 2) **Precision** (*точность*): показывает, какая доля объектов, для которой модель поставила целевой признак, действительно имеют целевой признак.\n","\n","$\\begin{align}\n","precision = \\frac{TP}{TP+FP}\n","\\end{align}$\n","\n","Точность определяет, как много отрицательных ответов нашла модель, пока искала положительные. Чем больше отрицательных, тем ниже точность.  \n","Вычисляется функцией `precision_score()`.\n","\n","``` python\n","from sklearn.metrics import precision_score\n","print(precision_score(target_valid, predicted_valid))\n","```"]},{"cell_type":"markdown","metadata":{"id":"-5BSW2FOmN63"},"source":["#### 3) **Recall** (*полнота*): выявляет, какую часть объектов, имеющих целевой признак, правильно определила модель.\n","\n","$\\begin{align}\n","recall = \\frac{TP}{TP+FN}\n","\\end{align}$\n","\n","Полнота — это доля TP-ответов среди всех, у которых истинная метка 1. Хорошо, когда значение *Recall* близко к единице: модель хорошо ищет положительные объекты. Если полнота ближе к нулю — модель надо перепроверить и починить.  \n","Вычисляется функцией `recall_score()`.\n","\n","``` python\n","from sklearn.metrics import recall_score\n","print(recall_score(target_valid, predicted_valid))\n","```"]},{"cell_type":"markdown","metadata":{"id":"fjvCYR-amosb"},"source":["#### 4) **F1-score** (*F1-мера*): агрегирующая метрика — среднее гармоническое полноты и точности.\n","\n","$\\begin{align}\n","F1\\text{-}score=\\frac{2 * precision * recall}{precision + recall}\n","\\end{align}$\n","\n","Если положительный класс плохо прогнозируется по одной из шкал (*Recall* или *Precision*), то близкая к нулю *F1-мера* покажет, что прогноз класса 1 не удался.  \n","Вычисляется функцией `f1_score()`.\n","\n","``` python\n","from sklearn.metrics import f1_score\n","print(f1_score(target_valid, predicted_valid))\n","```"]},{"cell_type":"markdown","metadata":{"id":"j5AQfdmUZw8u"},"source":["#### 5) **PR-кривая** (от англ. *Precision и Recall*)\n","\n","Показывает на графике значение точности `precision` и полноты `recall` при изменении порога. Чем выше кривая, тем лучше модель.\n","\n","Порог - граница, где заканчивается отрицательный класс и начинается положительный. По умолчанию он равен 0,5, но его можно поменять.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1FskmNXpBQfhVmHVu3N23fCweU38B9kVv\" alt=\"PR-кривая\" width=\"40%\"/>\n","\n","Вероятность классов вычисляет функция `predict_proba()`. На вход она получает признаки объектов, а возвращает вероятности классов.\n","``` python\n","probabilities = model.predict_proba(features)\n","print(probabilities)\n","```\n","результат:\n","``` python\n","[[0.5795 0.4205]\n"," [0.6629 0.3371]\n"," [0.7313 0.2687]\n"," [0.6728 0.3272]\n"," [0.5086 0.4914]] \n","```"]},{"cell_type":"markdown","metadata":{"id":"qhymVcCkgJqu"},"source":["#### 6) **TPR и FPR**\n","\n","Когда положительных объектов нет, точность не вычислить, но есть другие характеристики, в которых нет деления на ноль.\n","\n","**TPR** (англ. *True Positive Rate*) или «полнота», на английском используют термин *recall* - это доля верно предсказанных объектов к общему числу объектов класса.\n","\n","**FPR** (англ. *False Positive Rate*) - это доля ложных срабатываний к общему числу объектов за пределами класса.  \n","Отношение FP-ответов (*False Positives* — отрицательные, классифицированные как положительные) к сумме отрицательных ответов FP и TN (*True Negatives* — верно классифицированные отрицательные ответы).\n","\n","Деления на ноль не будет, т.к. в знаменателях значения, которые постоянны и не зависят от изменения модели.\n","\n","$\\begin{align}\n","TPR = \\frac{TP}{TP+FN} \\\\\n","FPR = \\frac{FP}{FP+TN}\n","\\end{align}$"]},{"cell_type":"markdown","metadata":{"id":"yLKLKXC1jTMa"},"source":["#### 7) **ROC-кривая** или **кривая ошибок** (от англ. *receiver operating characteristic*) и **AUC-ROC** (от англ. *Area Under Curve ROC* - «*площадь под ROC-кривой*»)\n","\n","Для модели, которая всегда отвечает случайно, ROC-кривая выглядит как прямая, идущая из левого нижнего угла в верхний правый. Чем график выше, тем больше значение TPR и лучше качество модели.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1FufAXL2wVglvlGH4mls17VXXlxrjTsVr\" alt=\"ROC-кривая\" width=\"60%\"/>\n","\n","Строят ROC-кривую с помощью функции `roc_curve()`. Она принимает на вход значения целевого признака и вероятности положительного класса, перебирает разные пороги и возвращает три списка: значения FPR, значения TPR и рассмотренные пороги.\n","\n","``` python\n","from sklearn.metrics import roc_curve\n","# создание и обучение модели\n","model = LogisticRegression(random_state=12345, solver='liblinear')\n","model.fit(features_train, target_train)\n","# прогнозирование вероятностей классов и выделение класса \"1\"\n","probabilities_valid = model.predict_proba(features_valid)\n","probabilities_one_valid = probabilities_valid[:, 1]\n","# получение параметров для ROC-кривой\n","fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n","# постороение ROC-кривой\n","plt.figure()\n","plt.plot(fpr, tpr)\n","# ROC-кривая случайной модели (выглядит как прямая)\n","plt.plot([0, 1], [0, 1], linestyle='--')\n","# параметры графика\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.0])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC-кривая')\n","plt.show()\n","```\n","\n","Чтобы выявить, на сколько сильно модель отличается от случайной, определяют **AUC-ROC** - площадь под ROC-кривой.  \n","Эта метрика качества изменяется от 0 до 1. AUC-ROC случайной модели равна 0.5. Вычисляется с помощью функции `roc_auc_score()`.\n","\n","``` python\n","from sklearn.metrics import roc_auc_score\n","auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n","```"]},{"cell_type":"markdown","metadata":{"id":"zddVmlSYT6H0"},"source":["### Модель \"дерево решений\" для задач классификации"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PefngpZfdoLt"},"outputs":[],"source":["import pandas as pd\n","\n","# импортирование модели \"дерево решений\"\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# загружаем исходный датасет\n","df = pd.read_csv('train_data.csv')\n","\n","# отдельно определили, что медиана выборки (средняя стоимость квартиры)\n","# равна 5650000 рублей\n","# создаем новый категориальный столбец ('price_class') - это целевая переменная\n","# для данной задачи, если \"дорого\", то 'price_class'=1,\n","# если \"дешево\", то 'price_class'=0\n","df.loc[df['last_price'] > 5650000, 'price_class'] = 1\n","df.loc[df['last_price'] <= 5650000, 'price_class'] = 0\n","\n","# делим исходный датасет на два:\n","# 1) один с параметрами (features), от которых зависит целевая переменная\n","# в нем не должно быть целевой переменной 'price_class')\n","# и в данной задаче не нужна цена квартиры, т.к. вместо неё мы ввели целевую\n","# переменную 'price_class'\n","# 2) второй с целевой переменной (target)\n","features = df.drop(['last_price', 'price_class'], axis=1)\n","target = df['price_class']\n","\n","# создаем модель типа \"дерево решений\"\n","model = DecisionTreeClassifier(random_state=12345)\n","\n","# обучаем модель на двух заполненных выборках с параметрами и целевой переменной\n","model.fit(features, target)\n","\n","# создаем два новых объекта с параметрами для тестирования модели\n","new_features = pd.DataFrame(\n","    [[900, 12, 2.8, 25, 409.7, 25, 0, 0, 0, 112, 0, 30706.0, 7877.0],\n","     [109, 2, 2.75, 25, 32, 25, 0, 0, 0, 40.5, 0, 36421.0, 9176.0]],\n","    columns=features.columns)\n","\n","# предсказываем ответы, загружая параметры двух новых тестовых объектов в модель\n","answers = model.predict(new_features)\n","# печатаем результат\n","print(answers)"]},{"cell_type":"markdown","metadata":{"id":"OsUIssQdoD0q"},"source":["### Глубина обучения\n","\n","**Переобучение** означает, что модель плохо поняла зависимости в данных. Модель хорошо объясняет примеры из обучающего набора данных, но плохо отрабатывает на тестовой выборке (значение параметра accuracy на тестовой выборке модели ниже, чем на обучающей).\n","\n","**Недообучение** - обратно переобучению, возникает, когда качество на обучающей и тестовой выборках примерно одинаковое и низкое.\n","\n","**Глубина дерева** (высота дерева) — это максимальное количество условий от «вершины» до финального ответа (считается по количеству переходов между узлами). Если дерево высокое (большое количество переходов между узлами/условиями), у модели склонность к переобучению; низкое — к недообучению. Решающее дерево с одним переходом (вопросом) называют \"пнем\" :). \n","\n","Глубина дерева (глубина обучения) в sklearn задаётся параметром max_depth.  \n","``` python\n","model = DecisionTreeClassifier(random_state=12345, max_depth=3)\n","```"]},{"cell_type":"markdown","metadata":{"id":"mnKjNjB7AK34"},"source":["### Модель \"случайный лес\" для задач классификации\n","\n","Алгоритм обучает большое количество независимых друг от друга деревьев, а потом принимает решение на основе голосования. Случайный лес помогает улучшить результат предсказания и избежать переобучения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgYebKjD_6sp"},"outputs":[],"source":["import pandas as pd\n","# импортируем модель \"случайный лес\"\n","from sklearn.ensemble import RandomForestClassifier\n","# импортируем функцию разделения выборки на обучающую и тестовую(валидационную)\n","from sklearn.model_selection import train_test_split\n","# импортируем функцию определения точности предсказаний модели\n","from sklearn.metrics import accuracy_score\n","\n","# загружаем выборку\n","df = pd.read_csv('/datasets/train_data.csv')\n","# добавляем в выборку целевой категорийный признак\n","df.loc[df['last_price'] > 5650000, 'price_class'] = 1\n","df.loc[df['last_price'] <= 5650000, 'price_class'] = 0\n","\n","# делим выборку на валидационную (25%) и обучающую (всё остальное - 75%)\n","# обязательно назначаем параметр random_state\n","# (любое значение, но потом его не меняем)\n","df_train, df_valid = train_test_split(df, test_size=.25, random_state=12345)\n","\n","# делим обучающую и валидационную выборки на наборы параметров\n","# и целевых значений\n","features_train = df_train.drop(['last_price', 'price_class'], axis=1)\n","target_train = df_train['price_class']\n","features_valid = df_valid.drop(['last_price', 'price_class'], axis=1)\n","target_valid = df_valid['price_class']\n","\n","# создаем модель типа \"случайный лес\"\n","# зададим, что в случайном лесу будет 10 деревьев (n_estimators=10)\n","model = RandomForestClassifier(random_state=12345, n_estimators=10)\n","\n","# обучаем модель на обучающей (тренировочной) выборке\n","model.fit(features_train, target_train)\n","\n","# получаем предсказания обученной модели на тестовой выборке\n","predictions = model.predict(features_valid)\n","# точность модели определяем функцией accuracy_score()\n","accuracy = accuracy_score(target_valid, predictions)\n","\n","# или методом .score(), который считает accuracy для всех алгоритмов\n","# классификации (а для всех моделей регрессии этот же метод .score()\n","# вычисляет метрику r2_score), в этом случае не нужен этап расчета\n","# model.predict(), т.к. метод .score() делает этот расчет внутри себя\n","result = model.score(features_valid, target_valid)"]},{"cell_type":"markdown","metadata":{"id":"5M7hlqNKKltr"},"source":["### Модель \"логистическая регрессия\" для задач классификации\n","\n","Не смотря на такое название, это алгоритм для задачи классификации, а не регрессии. Это логистическое уравнение придумал бельгийский математик Франсуа Ферхюльст. В логистической регрессии параметров мало, поэтому вероятность переобучения невелика."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SCAme99GK1_k"},"outputs":[],"source":["import pandas as pd\n","from joblib import dump\n","\n","# импортируем модель \"логистическая регрессия\"\n","from sklearn.linear_model import LogisticRegression\n","# импортируем функцию разделения выборки на обучающую и тестовую(валидационную)\n","from sklearn.model_selection import train_test_split\n","\n","# создаем модель типа \"логистической регрессии\"\n","# solver='lbfgs' - определяет алгоритм, который будет строить модель\n","# алгоритм 'lbfgs' из самых распространённых, подходит для большинства задач\n","# max_iter задаёт максимальное количество итераций обучения (по умолчанию 100)\n","model = LogisticRegression(random_state=12345, solver='lbfgs', max_iter=1000)\n","\n","# обучаем модель на обучающей (тренировочной) выборке\n","model.fit(features_train, target_train)\n","\n","# загружаем модель на сервер\n","dump(model, 'model_9_1.joblib')"]},{"cell_type":"markdown","metadata":{"id":"r_D73356bu7f"},"source":["Обучая логистическую регрессию, можно столкнуться с предупреждением библиотеки sklearn. Чтобы его отключить, указывают аргумент `solver='liblinear'` (англ. solver «алгоритм решения»; library linear, «библиотека линейных алгоритмов»):  \n","`model = LogisticRegression(solver='liblinear')`"]},{"cell_type":"markdown","metadata":{"id":"HasbgampRvi5"},"source":["### Сравнение моделей для задач классификации\n","\n","Модель | Качество (accuracy) | Скорость работы\n",":--- | :---: | :---:\n","**Дерево решений**\t| Низкое |\tВысокая\n","**Случайный лес**\t| Высокое |\tНизкая\n","**Логистическая регрессия** |\tСреднее |\tВысокая\n"]},{"cell_type":"markdown","metadata":{"id":"g53tMqX-3KG5"},"source":["## Модели для задач регрессии"]},{"cell_type":"markdown","metadata":{"id":"YFAiQ93TtPbi"},"source":["### Метрики качества моделей для задач регрессии\n"]},{"cell_type":"markdown","metadata":{"id":"s1UYONPZo91F"},"source":["#### 1) **MSE** (англ. *Mean Squared Error*)\n","\n","**Средняя квадратичная ошибка** - наиболее распространённая метрика качества в задаче регрессии. Чем MSE меньше, тем точнее модель.\n","\n","$\\begin{align}\n","MSE=\\frac{\\text{Сумма квадратов ошибок объектов}}{\\text{Количество объектов}}\n","\\end{align}$\n","\n","или\n","\n","$\\begin{align}\n","MSE=\\frac1N\\sum_{i=1}^N(y_i-\\hat{y}_i)^2\n","\\end{align}$\n","\n","Функция расчета средней квадратичной ошибки - `mean_squared_error()` из библиотеки `sklearn`.\n","\n","``` python\n","# импортируем функцию расчёта MSE из библиотеки sklearn\n","from sklearn.metrics import mean_squared_error\n","\n","# сформируем для примера правильные ответы и предсказания\n","answers = [623, 253, 150, 237]\n","predictions = [649, 253, 370, 148]\n","\n","# расчет MSE\n","result = mean_squared_error(answers, predictions)\n","```"]},{"cell_type":"markdown","metadata":{"id":"Uh9r6XCFtPvQ"},"source":["#### 2) **RMSE** (англ. *root mean squared error*)\n","\n","**Корень из средней квадратичной ошибки** - это квадратный корень из средней квадратичной ошибки (MSE). Применяют чтобы метрика показывала просто рубли, а не \"квадратные рубли\" как после расчета средней квадратичной ошибки (MSE). \n","\n","$\\begin{align}\n","RMSE = \\sqrt{\\frac1N\\sum_{i=1}^N(y_i-\\hat{y}_i)^2}=\\sqrt{MSE}\n","\\end{align}$\n","\n","``` python\n","# RMSE рассчитывается как квадратный корень из MSE:\n","result = mean_squared_error(answers, predictions) **.5\n","\n","# или сразу так:\n","result = mean_squared_error(answers, predictions, squared=False)\n","```"]},{"cell_type":"markdown","metadata":{"id":"MDPzMJRpwCsQ"},"source":["#### 3) **метрика R2** (англ. *coefficient of determination; R-squared*)\n","\n","**Коэффициент детерминации** - вычисляет долю средней квадратичной ошибки модели от MSE среднего, а затем вычитает эту величину из единицы. Увеличение метрики означает прирост качества модели.\n","- Значение метрики R2 равно единице только если MSE нулевое. Такая модель предсказывает все ответы идеально.\n","- R2 равно нулю: модель работает так же, как и среднее.\n","- Если метрика R2 отрицательна, то качество модели очень низкое.\n","- Значения R2 больше единицы быть не может.\n","\n","$\\begin{align}\n","R^2=1-\\frac{MSE(model)}{MSE(baseline)}\n","\\end{align}$\n","\n","Вычисляется функцией `r2_score()`.\n","\n","``` python\n","from sklearn.metrics import r2_score\n","# создание и обучение библиотеки, получение предсказаний\n","model = LinearRegression()\n","model.fit(features_train, target_train)\n","predicted_valid = model.predict(features_valid)\n","# расчет и вывод R2\n","print(\"R2 =\", r2_score(target_valid, predicted_valid))\n","```"]},{"cell_type":"markdown","metadata":{"id":"DmlQU6G8zb2C"},"source":["#### 4) **MAE (англ. mean absolute error)**\n","\n","**Среднее абсолютное отклонение** -  похожа на MSE, но в ней нет возведения в квадрат. Вычисляется функцией `mean_absolute_error()`.\n","\n","$\\begin{align}\n","MAE=\\frac1N\\sum_{i=1}^N|y_i-\\hat y_i|\n","\\end{align}$\n","\n","``` python\n","from sklearn.metrics import mean_absolute_error\n","print(mean_absolute_error(target_valid, predicted_valid))\n","```"]},{"cell_type":"markdown","metadata":{"id":"8WfWfmDNxWoD"},"source":["### Модель \"дерево решений\" для регрессии\n","\n","``` python\n","import pandas as pd\n","# импортируем модель \"дерево решений\" для регрессии\n","from sklearn.tree import DecisionTreeRegressor\n","# импортируем функцию разделения выборки на обучающую и тестовую(валидационную)\n","from sklearn.model_selection import train_test_split\n","# импортируем функцию для расчета MSE/RMSE\n","from sklearn.metrics import mean_squared_error\n","\n","# загрузка данных\n","df = pd.read_csv('/datasets/train_data.csv')\n","\n","# разделение исходных данных на набор параметров и набор целевых значений\n","# целевые значения переводим в млн. руб. (разделив на 1000000)\n","features = df.drop(['last_price'], axis=1)\n","target = df['last_price'] / 1000000\n","\n","# делим исходные данные, представленные двумя наборами `features` и `target`,\n","# на обучающую и валидационную выборки (каждая также представляется\n","# двумя наборами)\n","# для валидационной выборки выделяем 25% исходных данных\n","features_train, features_valid, target_train, target_valid = train_test_split(\n","    features, target, test_size=.25, random_state=12345)\n","\n","# в цикле перебираем глубину \"дерева решений\", проверяем качество модели\n","# через RMSE и определяем наилучшую модель (RMSE меньше)\n","best_model = None\n","best_result = 10000\n","best_depth = 0\n","for depth in range(1, 6):\n","    # создаем модель \"дерево решений\" для регрессии\n","    # с заданной глубиной max_depth\n","    model = DecisionTreeRegressor(random_state=12345, max_depth=depth)\n","    # обучаем модель на тренировочной выборке\n","    model.fit(features_train, target_train)\n","    # получаем предсказания модели на валидационной выборке\n","    predictions_valid = model.predict(features_valid)\n","    # считаем значение метрики RMSE на валидационной выборке\n","    result = mean_squared_error(target_valid, predictions_valid) **.5\n","    if result < best_result:\n","        best_model = model\n","        best_result = result\n","        best_depth = depth\n","\n","print(\"RMSE наилучшей модели на валидационной выборке:\", best_result,\n","      \"Глубина дерева:\", best_depth)\n","```"]},{"cell_type":"markdown","metadata":{"id":"mGrkS9PF10mv"},"source":["### Модель \"случайный лес\" для регрессии\n","\n","``` python\n","import pandas as pd\n","# импортируем модель \"случайный лес\" для регрессии\n","from sklearn.ensemble import RandomForestRegressor\n","# импортируем функцию разделения выборки на обучающую (тренировочную)\n","# и валидационную (тестовую)\n","from sklearn.model_selection import train_test_split\n","# импортируем функцию для расчета MSE/RMSE\n","from sklearn.metrics import mean_squared_error\n","\n","# загрузка данных\n","df = pd.read_csv('/datasets/train_data.csv')\n","\n","# разделение исходных данных на набор параметров и набор целевых значений\n","# целевые значения переводим в млн. руб. (разделив на 1000000)\n","features = df.drop(['last_price'], axis=1)\n","target = df['last_price'] / 1000000\n","\n","# делим исходные данные (представленные двумя наборами `features` и `target`)\n","# на обучающую и валидационную выборки (каждая также представляется \n","# двумя наборами)\n","# для валидационной выборки выделяем 25% исходных данных\n","features_train, features_valid, target_train, target_valid = train_test_split(\n","    features, target, test_size=.25, random_state=12345)\n","\n","# в цикле перебираем количество деревьев `est` с шагом 10\n","# и глубину `depth` \"случайного леса\"\n","# проверяем качество модели через RMSE и определяем наилучшую модель\n","# (у которой RMSE меньше)\n","best_model = None\n","best_result = 10000\n","best_est = 0\n","best_depth = 0\n","for est in range(10, 51, 10):\n","    for depth in range (1, 11):\n","        # инициализируем модель \"случайный лес\"\n","        # с количеством деревьев n_estimators=est, \n","        # глубиной max_depth=depth и фиксированным параметром random_state=12345\n","        model = RandomForestRegressor(random_state=12345, n_estimators=est,\n","                                      max_depth=depth)\n","        # обучаем модель на тренировочной выборке\n","        model.fit(features_train, target_train)\n","        # получаем предсказания модели на валидационной выборке\n","        predictions_valid = model.predict(features_valid)\n","        # считаем значение метрики rmse на валидационной выборке\n","        result = mean_squared_error(target_valid, predictions_valid,\n","                                    squared=False)\n","        if result < best_result:\n","            best_model = model\n","            best_result = result\n","            best_est = est\n","            best_depth = depth\n","\n","print(\"RMSE наилучшей модели на валидационной выборке:\", best_result,\n","      \"Количество деревьев:\", best_est, \"Максимальная глубина:\", depth)\n","```"]},{"cell_type":"markdown","metadata":{"id":"a-puokEPUxUv"},"source":["### Модель \"линейная регрессия\" для регрессии\n","\n","``` python\n","import pandas as pd\n","# импортируем модель \"линейная регрессия\" для регрессии\n","from sklearn.linear_model import LinearRegression\n","# импортируем функцию разделения выборки на обучающую (тренировочную)\n","# и валидационную (тестовую)\n","from sklearn.model_selection import train_test_split\n","# импортируем функцию для расчета MSE/RMSE\n","from sklearn.metrics import mean_squared_error\n","\n","# загрузка данных\n","df = pd.read_csv('/datasets/train_data.csv')\n","\n","# разделение исходных данных на набор параметров и набор целевых значений\n","# целевые значения переводим в млн. руб. (разделив на 1000000)\n","features = df.drop(['last_price'], axis=1)\n","target = df['last_price'] / 1000000\n","\n","# делим исходные данные (представленные двумя наборами `features` и `target`)\n","# на обучающую и валидационную выборки (каждая также представляется\n","# двумя наборами)\n","# для валидационной выборки выделяем 25% исходных данных\n","features_train, features_valid, target_train, target_valid = train_test_split(\n","    features, target, test_size=.25, random_state=12345)\n","\n","# инициализируем модель \"линейная регрессия\"\n","model = LinearRegression()\n","# обучаем модель на тренировочной выборке\n","model.fit(features_train, target_train)\n","# получаем предсказания модели на валидационной выборке\n","predictions_valid = model.predict(features_valid)\n","# считаем значение метрики RMSE на валидационной выборке\n","result = mean_squared_error(target_valid, predictions_valid) ** .5\n","\n","print(\"RMSE модели линейной регрессии на валидационной выборке:\", result)\n","```"]},{"cell_type":"markdown","metadata":{"id":"tYINlZLlfiG6"},"source":["## Рекомендации по выбору лучшей модели\n","\n","Иногда (и даже, похоже, всегда) нужно перебирать разные варианты моделей, задавая разные гиперпараметры, сравнивать их результаты и на этом основании выбирать лучшую модель."]},{"cell_type":"markdown","metadata":{"id":"qBu8vEU-hNPE"},"source":["## Подготовка признаков\n","\n","В задачах машинного обучения к анализу готовят не только данные, но ещё и признаки. Модели обучаются на числовых данных, поэтому пропуски в данных и нечисловые значения могут вызвать ошибку и невозможность обучения модели.  \n","(признаки - это данные в выборках `features`, где нет целевого признака)"]},{"cell_type":"markdown","metadata":{"id":"Dj5hbLnCJ9d0"},"source":["### Разделение признаков по видам\n","\n","Для удобства обработки (кодирования, масштабирования и т.п.) формируют списки столбцов признаков по видам, как минимум, делят на категориальные признаки и числовые. Они обрабатываются разными функциями, а после обработки собираются обратно в выборки признаков `features`.  \n","Функции предобработки признаков, также как и модели, обучаются на признаках обучающей выборки, а потом обученные на обучающей выборке функции предобработки применяются к признакам обучающей, валидационной и тестовой выборок.\n","\n","Пример такого формирования списков столбцов с категориальными и численными признаками:\n","\n","``` python\n","# сформируем список категориальных признаков\n","# признаки 'has_cr_card' и 'is_active_member' уже имеют нужный формат\n","# и не требуют обработки\n","list_category = features_train.select_dtypes(include='object').columns.to_list()\n","#list_category.extend(['has_cr_card', 'is_active_member'])\n","print(f'''\n","Список категориальных признаков:\n","{list_category}''')\n","\n","# сформируем список численных признаков\n","list_numeral = features_train.select_dtypes(exclude='object').columns.to_list()\n","# признаки 'has_cr_card' и 'is_active_member' категориальные (бинарные 0/1),\n","# хоть и имеют в датасете тип численных, исключаем их из списка\n","list_numeral.remove('has_cr_card')\n","list_numeral.remove('is_active_member')\n","print(f'''\n","Список численных признаков:\n","{list_numeral}''')\n","```\n","Результат:\n","```\n","Список категориальных признаков:\n","['geography', 'gender']\n","\n","Список численных признаков:\n","['credit_score', 'age', 'tenure', 'balance', 'num_of_products', 'estimated_salary']\n","```"]},{"cell_type":"markdown","metadata":{"id":"0gkkJY2vA7jO"},"source":["### Техника прямого кодирования (англ. *One-Hot Encoding*, *OHE*).\n","\n","Позволяет преобразовать категориальные признаки в численные.  \n","Подходит для моделей \"логистическая реграссия\", \"решающее дерево\", \"случайный лес\".  \n","В частности, принадлежность к категории логистическая регрессия вычисляет по формуле, состоящей из признаков. Они могут быть только численные.\n","\n","Категориальные признаки переводятся в численные в два этапа:\n","1. Для каждого значения признака создаётся новый столбец.\n","2. Если объекту категория подходит, в новом столбце ставится 1, если нет — 0.\n","\n","Новые признаки (новые столбцы) называются *дамми-переменными* или *дамми-признаками* (англ. dummy variable, «фиктивная переменная»).\n","\n","Функция `pd.get_dummies()` из библиотеки `pandas` реализует технику прямого кодирования.\n","\n","*Важно!*  \n","Из всего переданного датафрейма, функция `pd.get_dummies()` обрабатывает только категориальные (нечисловые) столбцы (object). Она сама определяет их по типу данных столбцов (можно посмотреть через `.info()` или `.dtypes`).\n","\n","Пример применения функции `pd.get_dummies()` для столбца \"Gender\" датасета (с распечаткой первых значений):\n","```python\n","print(pd.get_dummies(data['Gender']).head())\n","```\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1BnhsuMdm4tsVHaSUEbKuhzjPXUiuxnG3\" alt=\"Пример применения техники One-Hot Encoding\" width=\"50%\"/>"]},{"cell_type":"markdown","metadata":{"id":"uzz4mMp8cNa_"},"source":["При отработке техники прямого кодирования One-Hot Encoding можно столкнуться с так называемой *дамми-ловушкой* (англ. dummy trap, «ловушка фиктивных признаков»), когда столбцы, добавляемые в датасет функцией `pd.get_dummies()`, сильно взаимосвязаны между собой. Это означает избыточность данных, что плохо для обучения.  \n","В примере с обработакой техникой прямого кодирования столбца `'Gender'` это, например, столбец `'Gender_F'`, значения которого однозначно можно определить исходя из значений двух других столбцов `'Gender_M'` и `'Gender_None'`. Соответственно, столбец `'Gender_F'` лишний и его нужно удалить.  \n","Удаление осуществляется с помощью параметра `drop_first=True` функции `pd.get_dummies()`.  \n","Пример:\n","``` python\n","data_ohe = pd.get_dummies(data['Gender'], drop_first=True)\n","```\n","\n","Альтернативный пример реализации техники прямого кодирования.  \n","Использование функции `OneHotEncoder()` (более предпочтительно, чем `pd.get_dummies()`).\n","\n","``` python\n","# отключение предупреждения 'SettingWithCopy'\n","pd.options.mode.chained_assignment = None\n","# кодирование категориальных признаков в обучающей выборке,\n","# имена столбцов в списке 'list_category'\n","encoder = OneHotEncoder(drop='first', sparse=False)\n","features_train[encoder.get_feature_names()] = encoder.fit_transform(\n","                                              features_train[list_category])\n","# после обработки добавились новые столбцы, образованные из исходных,\n","# старые столбцы удаляем\n","features_train = features_train.drop(list_category, axis=1)\n","\n","# кодирование категориальных признаков в валидационной выборке энкодером,\n","# который уже обучен на обучающей выборке\n","features_valid[encoder.get_feature_names()] = encoder.transform(\n","                                              features_valid[list_category])\n","# удаляем старые, теперь не нужные столбцы\n","features_valid = features_valid.drop(list_category, axis=1)\n","```"]},{"cell_type":"markdown","metadata":{"id":"5Qd_DnZV1eBl"},"source":["### Техника порядкового кодирования\n","\n","Также преобразует категориальные признаки в численные.  \n","Подходит для моделей \"решающее дерево\" и \"случайный лес\". Для \"логистической регрессии\" не подходит, так как .  \n","Кодирует цифрами выраженные категории в столбцах. Ordinal Encoding (от англ. «кодирование по номеру категории»). Работает следующим образом:\n","- Фиксируется, какой цифрой кодируется класс.\n","- Цифры размещаются в столбце.\n","\n","Функция для применения техники прямого кодирования `OrdinalEncoder()` находится в модуле `sklearn.preprocessing`.\n","\n","*Важно!*  \n","Функция `OrdinalEncoder()` перекодирует все столбцы в переданном ей датасете и категориальные и числовые. Данные в числовых столбцах изменятся!\n","\n","``` python\n","# импортируем OrdinalEncoder из библиотеки\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","# Преобразование выполняется в три этапа:\n","# 1. Создаём объект этой структуры данных\n","encoder = OrdinalEncoder()\n","# 2. Вызываем метод fit(), чтобы получить список категориальных признаков\n","encoder.fit(data)\n","# 3. Преобразуем данные функцией transform()\n","data_ordinal = encoder.transform(data)\n","\n","# преобразуем в датафрейм с названиями столбцов, как в исходном data\n","data_ordinal = pd.DataFrame(encoder.transform(data), columns=data.columns)\n","```\n","\n","``` python\n","# два варианта написания `fit()` и `transform()` в одну строку\n","# (результат одинаковый):\n","# первый\n","data_ordinal = pd.DataFrame(encoder.fit(data).transform(data), columns=data.columns)\n","# второй\n","data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)\n","```\n","<img src=\"https://drive.google.com/uc?export=view&id=1BuFSUAvBx8tY8iyAve-9o9OJjaDJ6rck\" alt=\"Пример применения техники Ordinal Encoding\" width=\"40%\"/>\n","\n","Пример кода с применением порядкового кодирования Ordinal Encoding и обучения модели \"решающее дерево\":\n","``` python\n","# импортирование необходимых библиотек и функций\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.preprocessing import OrdinalEncoder\n","# загрузка данных\n","data = pd.read_csv('/datasets/travel_insurance.csv')\n","# применение прямого кодирования\n","encoder = OrdinalEncoder()\n","data_ordinal = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)\n","# деление выборки на обучающую и валидационную\n","target = data_ordinal['Claim']\n","features = data_ordinal.drop('Claim', axis=1)\n","features_train, features_valid, target_train, target_valid = train_test_split(\n","                        features, target, test_size=0.25, random_state=12345)\n","# обучение модели \"решающее дерево\" на обучающей выборке\n","model = DecisionTreeClassifier(random_state=12345)\n","model.fit(features_train, target_train)\n","```\n","\n","Техника порядкового кодирования `Ordinal Encoding` используется реже, чем техника прямого кодирования `One-Hot Encoding`."]},{"cell_type":"markdown","metadata":{"id":"b4hyYpWacyIC"},"source":["### Масштабирование признаков\n","\n","Часто признаки имеют разный масштаб, поэтому их нужно выравнивать - стандартизировывать.  \n","Например, в столбце `Age` возможен возраст от 0 до 100 лет, а в столбце `Commission` страховая комиссия от 100 долларов до 1000. Значения и их разбросы в столбце Commission больше, поэтому алгоритм автоматически решит, что этот признак важнее возраста. А на самом дела для нас все признаки одинаково значимы.  \n","Чтобы избежать этой ловушки, признаки масштабируют — приводят к одному масштабу.\n","Один из методов масштабирования — **стандартизация данных**.\n","\n","Функция `StandardScaler()` из модуля `sklearn.preprocessing` используется для стандартизации данных.\n","``` python\n","# импортирование функции масштабирования данных\n","from sklearn.preprocessing import StandardScaler\n","# создание объекта функции масштабирования данных и настройка его на обучающих данных\n","# (настройка — это вычисление среднего и дисперсии)\n","scaler = StandardScaler()\n","scaler.fit(features_train)\n","# преобразование (масштабирование) обучающей и валидационной выборки функцией `transform()`\n","features_train_scaled = scaler.transform(features_train)\n","features_valid_scaled = scaler.transform(features_valid)\n","```\n","\n","При записи изменённых признаков в исходный датафрейм код может вызывать предупреждение `SettingWithCopy`. Причина этого в особенности поведения `sklearn` и `pandas`.  Чтобы предупреждение не появлялось, в код добавляют строчку:\n","``` python\n","pd.options.mode.chained_assignment = None\n","```\n","\n","*Важно!*  \n","масштабирование функцией `StandardScaler()` применяется к числовым данным, поэтому в методах `.fit()` и `.transform()` этой функции надо передавать только столбцы датасета с числовыми данными.\n","\n","Пример кода с применением масштабирования с помощью функции `StandardScaler()`:\n","``` python\n","# импортирование необходимых библиотек\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","# отключение предупреждения, связанного с работой функции `StandardScaler()`\n","pd.options.mode.chained_assignment = None\n","# загрузка данных\n","data = pd.read_csv('/datasets/travel_insurance.csv')\n","# разделение выборки на обучающую и валидационную\n","target = data['Claim']\n","features = data.drop('Claim', axis=1)\n","features_train, features_valid, target_train, target_valid = train_test_split(\n","    features, target, test_size=0.25, random_state=12345)\n","# список числовых столбцов для масштабирования\n","numeric = ['Duration', 'Net Sales', 'Commission (in value)', 'Age']\n","# инициация и обучение функции масштабирования\n","scaler = StandardScaler()\n","scaler.fit(features_train[numeric])\n","# применение функции масштабирования\n","features_train[numeric] = scaler.transform(features_train[numeric])\n","features_valid[numeric] = scaler.transform(features_valid[numeric])\n","# просмотр результатов в обучающей выборке\n","print(features_train.head())\n","```"]},{"cell_type":"markdown","metadata":{"id":"q-MFDaq7Ic8f"},"source":["## Балансирование классов\n","\n","Для балансировки классов применяют следующие техники:\n","- Взвешивание классов.\n","- Изменение размеров выборки (масштабирование или стандартизация):\n","  - увеличение выборки (upsampling);\n","  - уменьшение выборки (downsampling)."]},{"cell_type":"markdown","metadata":{"id":"lECqrUoZR2Nw"},"source":["### Техника взвешивания классов\n","\n","Для балансировки классов при создании моделей используется параметр `class_weight='balanced'`, который есть в функциях создания моделей `DecisionTreeClassifier()`, `RandomForestClassifier()` и `LogisticRegression()`. Он увеличивает вес класса, которого меньше. Например, если \"1\" в 3 раза меньше, чем \"0\", то у \"0\" будет вес 1, а у \"1\" будет вес 3.\n","\n","Пример:\n","\n","``` python\n","model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n","```"]},{"cell_type":"markdown","metadata":{"id":"UyFbE31VS6y8"},"source":["### Техника \"upsampling\"\n","\n","Преобразование проходит в несколько этапов:\n","- разделить обучающую выборку на отрицательные и положительные объекты;\n","- скопировать несколько раз положительные объекты;\n","- с учётом полученных данных создать новую обучающую выборку;\n","- перемешать данные.\n","\n","Перемешивание данных осуществляется с помощью функции `upsample()`.  \n","Объем выборки после применения \"upsampling\" увеличивается.\n","\n","Пример балансировки выборки в которой \"1\" меньше \"0\" в 4 раза:\n","\n","``` python\n","# делим обучающие выборки на отрицательные и положительные объекты\n","features_zeros = features_train_balans[target_train_balans == 0]\n","features_ones = features_train_balans[target_train_balans == 1]\n","target_zeros = target_train_balans[target_train_balans == 0]\n","target_ones = target_train_balans[target_train_balans == 1]\n","\n","# увеличиваем количество положительных объектов в 4 раза путем копирования\n","features_train_upsampled = pd.concat([features_zeros] + [features_ones] * 4)\n","target_train_upsampled = pd.concat([target_zeros] + [target_ones] * 4)\n","\n","# перемешиваем\n","features_train_upsampled, target_train_upsampled = shuffle(\n","  features_train_upsampled, target_train_upsampled, random_state=12345)\n","```"]},{"cell_type":"markdown","metadata":{"id":"id3lZeNDU5-Z"},"source":["### Техника \"downsampling\"\n","\n","Преобразование проходит в несколько этапов:\n","- разделить обучающую выборку на отрицательные и положительные объекты;\n","- случайным образом отбросить часть из отрицательных объектов;\n","- с учётом полученных данных создать новую обучающую выборку;\n","- перемешать данные.\n","\n","Чтобы удалить из выборки случайные элементы, применяется функция `sample()`. На вход она принимает аргумент `frac`. Возвращает случайные элементы в таком количестве, чтобы их доля от исходной таблицы была равна `frac`.  \n","Объем выборки после применения \"downsampling\" уменьшается.\n","\n","Пример балансировки выборки сокращением доли \"0\" до 0,1:\n","\n","``` python\n","# делим обучающие выборки на отрицательные и положительные объекты\n","features_zeros = features[target == 0]\n","features_ones = features[target == 1]\n","target_zeros = target[target == 0]\n","target_ones = target[target == 1]\n","# сокращаем долю \"0\" в 10 раз, удаляя и оставляя их долю\n","# в размере 0,1 от исходной выборки \"0\"\n","features_downsampled = pd.concat([features_zeros.sample(\n","  frac=.1, random_state=12345)] + [features_ones])\n","target_downsampled = pd.concat([target_zeros.sample(\n","  frac=.1, random_state=12345)] + [target_ones])\n","# перемешиваем\n","features_downsampled, target_downsampled = shuffle(\n","  features_downsampled, target_downsampled, random_state=12345)\n","```"]}],"metadata":{"colab":{"provenance":[{"file_id":"1DOXUNkzMGuhS4jc5zAYXBX9pW4TXf9Pi","timestamp":1674102012332}],"authorship_tag":"ABX9TyPCjOijBDuBWaO22Yujh70q"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}